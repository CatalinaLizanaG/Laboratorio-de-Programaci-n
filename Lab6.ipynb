{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "ac9155b9f5e04400957a6f8bb3f6610c",
    "deepnote_cell_type": "markdown",
    "id": "2v2D1coL7I8i"
   },
   "source": [
    "<h1><center>Laboratorio 6: La solicitud de Sergio ü§ó</center></h1>\n",
    "\n",
    "<center><strong>MDS7202: Laboratorio de Programaci√≥n Cient√≠fica para Ciencia de Datos - Primavera 2024</strong></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d3d6f6d405c54dbe985a5f4b3e4f9120",
    "deepnote_cell_type": "markdown",
    "id": "YxdTmIPD7L_x"
   },
   "source": [
    "### Cuerpo Docente:\n",
    "\n",
    "- Profesores: Ignacio Meza, Sebasti√°n Tinoco\n",
    "- Auxiliar: Eduardo Moya\n",
    "- Ayudantes: Nicol√°s Ojeda, Melanie Pe√±a, Valentina Rojas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "851a7788e8214942863cbd4099064ab2",
    "deepnote_cell_type": "markdown",
    "id": "Y2Gyrj-x7N2L"
   },
   "source": [
    "### Equipo: SUPER IMPORTANTE - notebooks sin nombre no ser√°n revisados\n",
    "\n",
    "- Nombre de alumno 1: Cristobal Ramos\n",
    "- Nombre de alumno 2: Catalina Lizana\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "f23a189afdec4e198683308db70e43b7",
    "deepnote_cell_type": "markdown",
    "id": "jQ9skYc57Pxi"
   },
   "source": [
    "### **Link de repositorio de GitHub:** [Repositorio](https://github.com/CatalinaLizanaG/Laboratorio-de-Programaci-n.git)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "b5318f41cda64d4290a7a548956ed725",
    "deepnote_cell_type": "markdown",
    "id": "1M4PoEWm7S80"
   },
   "source": [
    "## Temas a tratar\n",
    "- Aplicar Pandas para obtener caracter√≠sticas de un DataFrame.\n",
    "- Aplicar Pipelines y Column Transformers.\n",
    "- Utilizar diferentes algoritmos de cluster y ver el desempe√±o.\n",
    "\n",
    "## Reglas:\n",
    "\n",
    "- **Grupos de 2 personas**\n",
    "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser√°n respondidos por este medio.\n",
    "- Prohibidas las copias.\n",
    "- Pueden usar cualquer matrial del curso que estimen conveniente.\n",
    "- C√≥digo que no se pueda ejecutar, no ser√° revisado.\n",
    "\n",
    "### Objetivos principales del laboratorio\n",
    "- Comprender c√≥mo aplicar pipelines de Scikit-Learn para generar clusters.\n",
    "- Familiarizarse con plotly.\n",
    "\n",
    "El laboratorio deber√° ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al m√°ximo las funciones optimizadas que nos entrega `numpy`, las cuales vale mencionar, son bastante m√°s eficientes que los iteradores nativos sobre arreglos (*o tensores*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "858df483d9e64780a21674afed1d34b8",
    "deepnote_cell_type": "markdown",
    "id": "SuMbiyQZG2Cc"
   },
   "source": [
    "## Descripci√≥n del laboratorio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "403ffe48ec994afda4b91e670a08d0ef",
    "deepnote_cell_type": "markdown",
    "id": "QZsNO4rUrqCz"
   },
   "source": [
    "<center>\n",
    "<img src=\"https://i.pinimg.com/originals/5a/a6/af/5aa6afde8490da403a21601adf7a7240.gif\" width=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0303baa17d4546feae8c9b88c58470bf",
    "deepnote_cell_type": "markdown",
    "id": "2o0MPuk8rqCz"
   },
   "source": [
    "En el coraz√≥n de las operaciones de Aerol√≠nea Lucero, Sergio, el gerente de an√°lisis de datos, reuni√≥ a un talentoso equipo de j√≥venes cient√≠ficos de datos para un desaf√≠o crucial: segmentar la base de datos de los clientes. ‚ÄúNuestro objetivo es descubrir patrones en el comportamiento de los pasajeros que nos permitan personalizar servicios y optimizar nuestras campa√±as de marketing,‚Äù explic√≥ Sergio, mientras desplegaba un amplio rango de datos que inclu√≠an desde h√°bitos de compra hasta opiniones sobre los vuelos.\n",
    "\n",
    "Sergio encarg√≥ a los cient√≠ficos de datos la tarea de aplicar t√©cnicas avanzadas de clustering para identificar distintos segmentos de clientes, como los viajeros frecuentes y aquellos que eligen la aerol√≠nea para celebrar ocasiones especiales. La meta principal era entender profundamente c√≥mo estos grupos perciben la calidad y satisfacci√≥n de los servicios ofrecidos por la aerol√≠nea.\n",
    "\n",
    "A trav√©s de un enfoque meticuloso y colaborativo, los cient√≠ficos de datos se abocaron a la tarea, buscando transformar los datos brutos en valiosos insights que permitir√≠an a Aerol√≠nea Lucero no solo mejorar su servicio, sino tambi√©n fortalecer las relaciones con sus clientes mediante una oferta m√°s personalizada y efectiva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e78cb41b144041af98928ab26dcfdaa9",
    "deepnote_cell_type": "markdown",
    "id": "hs4KKWF1Hdpo"
   },
   "source": [
    "## Importamos librerias utiles üò∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install scikit-learn\n",
    "#!pip install plotly.express"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "95a5533cfd6d49cfb9afc111c44d224f",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 15,
    "execution_start": 1714107106552,
    "id": "a4YpMafirqC0",
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "acbeab32db6146678e75448dddf43da8",
    "deepnote_cell_type": "markdown",
    "id": "UQOXod4gHhSq"
   },
   "source": [
    "## 1. Estudio de Performance üìà [10 Puntos]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "704b56b978254ad3ae12cdbf58f4832d",
    "deepnote_cell_type": "markdown",
    "id": "Gn5u5ICkrqC2"
   },
   "source": [
    "<center>\n",
    "<img src=\"https://user-images.githubusercontent.com/57133330/188281408-c67df9ee-fd1f-4b37-833b-f02848f1ce02.gif\" width=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d35fbdcc5ef045d6a2822622f0714179",
    "deepnote_cell_type": "markdown",
    "id": "y4Z0jTjtrqC2"
   },
   "source": [
    "Don Sergio les ha encomendado su primera tarea: analizar diversas t√©cnicas de clustering. Su objetivo es entender detalladamente c√≥mo funcionan estos m√©todos en t√©rminos de segmentaci√≥n y eficiencia en tiempo de ejecuci√≥n.\n",
    "\n",
    "Analice y compare el desempe√±o, tiempo de ejecuci√≥n y visualizaciones de cuatro algoritmos de clustering (k-means, DBSCAN, Ward y GMM) aplicados a tres conjuntos de datos, incrementando progresivamente su tama√±o. Utilice Plotly para las gr√°ficas y discuta los resultados tanto cualitativa como cuantitativamente.\n",
    "\n",
    "Uno de los requisitos establecidos por Sergio es que el an√°lisis se lleve a cabo utilizando Plotly; de no ser as√≠, se considerar√° incorrecto. Para facilitar este proceso, se ha proporcionado un c√≥digo de Plotly que puede servir como base para realizar las gr√°ficas. Ap√≥yese en el c√≥digo entregado para efectuar el an√°lisis y tome como referencia la siguiente imagen para realizar los gr√°ficos:\n",
    "\n",
    "<img src='https://gitlab.com/imezadelajara/datos_clase_7_mds7202/-/raw/main/misc_images/Screenshot_2024-04-26_at_9.10.44_AM.png' width=800 />\n",
    "\n",
    "En el gr√°fico se visualizan en dos dimensiones los diferentes tipos de datos proporcionados en `datasets`. Cada columna corresponde a un modelo de clustering diferente, mientras que cada fila representa un conjunto de datos distinto. Cada uno de los gr√°ficos incluye el tiempo en segundos que tarda el an√°lisis y la m√©trica Silhouette obtenida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "37580aab6cef4238a8ce42c50a6d35de",
    "deepnote_cell_type": "markdown",
    "id": "maCUNAvZrqC2"
   },
   "source": [
    "Para ser m√°s espec√≠ficos, usted debe cumplir los siguientes objetivos:\n",
    "1. Generar una funci√≥n que permita replicar el gr√°fico expuesto en la imagen (no importa que los colores calcen). [4 puntos]\n",
    "2. Ejecuta la funci√≥n para un `n_samples` igual a 1000, 5000, 10000. [2 puntos]\n",
    "3. Analice y compare el desempe√±o, tiempo de ejecuci√≥n y visualizaciones de cuatro algoritmos de clustering utilizando las 3 configuraciones dadas en `n_samples`. [4 puntos]\n",
    "\n",
    "\n",
    "> ‚ùó Tiene libertad absoluta de escoger los hiper par√°metros de los cluster, sin embargo, se recomienda verificar el dominio de las variables para realizar la segmentaci√≥n.\n",
    "\n",
    "> ‚ùó Recuerde que es obligatorio el uso de plotly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "7f7c25e366754595b13fc2e8116f65a0",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 78,
    "execution_start": 1714107108441,
    "id": "i0IZPGPOrqC3",
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "En la siguiente celda se crean los datos ficticios a usar en la secci√≥n 1 del lab.\n",
    "‚ùóNo realice cambios a esta celda a excepci√≥n de n_samples‚ùó\n",
    "\"\"\"\n",
    "\n",
    "# Datos a utilizar\n",
    "\n",
    "# Configuracion\n",
    "n_samples = 5000 #Este par√°metro si lo pueden modificar\n",
    "\n",
    "def create_data(n_samples):\n",
    "\n",
    "    # Lunas\n",
    "    moons = datasets.make_moons(n_samples=n_samples, noise=0.05, random_state=30)\n",
    "    # Blobs\n",
    "    blobs = datasets.make_blobs(n_samples=n_samples, random_state=172)\n",
    "    # Datos desiguales\n",
    "    transformation = [[0.6, -0.6], [-0.4, 0.8]]\n",
    "    mutated = (np.dot(blobs[0], transformation), blobs[1])\n",
    "\n",
    "    # Generamos Dataset\n",
    "    dataset = {\n",
    "        'moons':{\n",
    "            'x': moons[0], 'classes': moons[1], 'n_cluster': 2\n",
    "        },\n",
    "        'blobs':{\n",
    "            'x': blobs[0], 'classes': blobs[1], 'n_cluster': 3\n",
    "        },\n",
    "        'mutated':{\n",
    "            'x': mutated[0], 'classes': mutated[1], 'n_cluster': 3\n",
    "        }\n",
    "    }\n",
    "    return dataset\n",
    "\n",
    "data_sets = create_data(n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y51s6f_UtIkc"
   },
   "source": [
    "**Respuestas:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "643d6b35af5541358f481fda4d3fc51f",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 267,
    "execution_start": 1714108733824,
    "id": "CO3JFqezrqC3",
    "outputId": "61a8cca1-3460-44dc-c23f-7dffb853b9a6",
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "#1. Generar una funci√≥n que permita replicar el gr√°fico expuesto en la imagen \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from scipy.cluster.hierarchy import ward\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#def plot_scatter(x,y, color):\n",
    "def plot_scatter(data_sets):\n",
    "    datas = {'Moons': {'data':data_sets['moons']['x'],'cluster':2}, \n",
    "             'Blobs': {'data': data_sets['blobs']['x'],'cluster':3}, \n",
    "             'Mutated':{'data':data_sets['mutated']['x'],'cluster':3}\n",
    "            }\n",
    "    fig = make_subplots(rows=3, cols=4, subplot_titles=('KMeans', 'GMM', 'Ward', 'DBSCAN'))\n",
    "    \n",
    "    \n",
    "    for i, figure in enumerate(datas.items()):\n",
    "        \n",
    "        data = figure[1]['data']\n",
    "        cluster= figure[1]['cluster']\n",
    "        df = pd.DataFrame(data, columns=['x', 'y'])\n",
    "        \n",
    "        # kmeans\n",
    "        kmeans = KMeans(n_clusters=cluster, random_state=0)\n",
    "        start_time = time.time()\n",
    "        df['Kmeans'] = kmeans.fit(data).labels_\n",
    "        t = time.time() - start_time\n",
    "\n",
    "        sc= silhouette_score(data, df['Kmeans']).round(2)\n",
    "        #df['Kmeans'] = df['Kmeans'].astype(str)\n",
    "        scatter_kmeans = px.scatter(df, x='x', y='y', color='Kmeans')\n",
    "        fig.add_trace(scatter_kmeans.data[0], row=i+1, col=1)\n",
    "        fig.add_annotation(xref=\"paper\", yref=\"paper\", x = 0.05, y= 1-0.25*(i+1), text= str(round(t,2))+ \"[s]| s:\" +str(sc),showarrow=False)\n",
    "        \n",
    "        # GMM\n",
    "        GMM = GaussianMixture(n_components = cluster, random_state=0)\n",
    "        start_time = time.time()\n",
    "        df['GMM'] = GMM.fit(data).predict(data)\n",
    "        t = time.time() - start_time\n",
    "        \n",
    "        sc= silhouette_score(data, df['GMM']).round(2)\n",
    "        #df['GMM'] = df['GMM'].astype(str)\n",
    "        scatter_gmm = px.scatter(df, x='x', y='y', color='GMM')\n",
    "        fig.add_trace(scatter_gmm.data[0], row=i+1, col=2)\n",
    "        fig.add_annotation(xref=\"paper\", yref=\"paper\",  x= 0.35, y=1-0.25*(i+1), text= str(round(t,2))+ \"[s]| s:\" +str(sc),showarrow=False)\n",
    "        \n",
    "        # Ward\n",
    "        Ward = AgglomerativeClustering(n_clusters=cluster, linkage=\"ward\")\n",
    "        start_time = time.time()\n",
    "        df['Ward'] = Ward.fit(data).labels_\n",
    "        t = time.time() - start_time\n",
    "        \n",
    "        sc= silhouette_score(data, df['Ward']).round(2)\n",
    "        #df['Ward'] = df['Ward'].astype(str)\n",
    "        scatter_ward = px.scatter(df, x='x', y='y', color='Ward')\n",
    "        fig.add_trace(scatter_ward.data[0], row=i+1, col=3)\n",
    "        fig.add_annotation(xref=\"paper\", yref=\"paper\", x = 0.65, y=1-0.25*(i+1), text= str(round(t,2))+ \"[s]| s:\" +str(sc),showarrow=False)\n",
    "    \n",
    "        # Dbscan\n",
    "        dbscan = DBSCAN(eps=0.2, min_samples=10)\n",
    "        start_time = time.time()\n",
    "        df['dbscan'] = dbscan.fit(data).labels_\n",
    "        t = time.time() - start_time\n",
    "        \n",
    "        sc= silhouette_score(data, df['dbscan']).round(2)\n",
    "        #df['dbscan'] = df['dbscan'].astype(str)\n",
    "        scatter_dbscan = px.scatter(df, x='x', y='y', color='dbscan')\n",
    "        fig.add_trace(scatter_dbscan.data[0], row=i+1, col=4)\n",
    "        fig.add_annotation(xref=\"paper\", yref=\"paper\", x = 0.95, y= 1-0.25*(i+1), text= str(round(t,2))+ \"[s]| s:\" +str(sc),showarrow=False)\n",
    "            \n",
    "    fig.update_layout(height=750, width=1000, title_text='Comparaci√≥n de tiempos de ejecuci√≥n por t√©cnica', showlegend=True)\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Ejecuta la funci√≥n para un n_samples igual a 1000, 5000, 10000\n",
    "datasets1 = create_data(1000)\n",
    "plot_scatter(datasets1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets2 = create_data(5000)\n",
    "plot_scatter(datasets2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets3 = create_data(10000)\n",
    "plot_scatter(datasets3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Analice y compare el desempe√±o, tiempo de ejecuci√≥n y visualizaciones de cuatro algoritmos de clustering utilizando las 3 configuraciones dadas en n_samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notamos que cuando tenemos m√°s muestras los graficos y las mediciones toman m√°s tiempo, sin embargo, se evidencia que independiente de la cantidad de muestras:\n",
    "* El mejor clustering de Moons es DBSCAN\n",
    "* El mejor clusterion de Bolbs con 'KMeans', 'GMM' y 'Ward', con igual desempe√±o de los tre.\n",
    "* Para Mutated, GMM nos da un mejor clustering, lo cual tiene sentido considerando que se visualizan muestras gaussianas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "13c5cb8067d9415f83b3d497954a437a",
    "deepnote_cell_type": "markdown",
    "id": "3mCbZc86rqC6"
   },
   "source": [
    "## 2. An√°lisis de Satisfacci√≥n de Vuelos. [10 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "fd6e991646b44f50a4b13f01d1542415",
    "deepnote_cell_type": "markdown",
    "id": "JI33m5jbrqC6"
   },
   "source": [
    "<center>\n",
    "<img src=\"https://i.gifer.com/2Hci.gif\" width=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "5742dfbd5a2e43778ff250436bab1005",
    "deepnote_cell_type": "markdown",
    "id": "h5k24znirqC7"
   },
   "source": [
    "Habiendo entendido c√≥mo funcionan los modelos de aprendizaje no supervisado, *Don Sergio* le encomienda estudiar la satisfacci√≥n de pasajeros al haber tomado un vuelo en alguna de sus aerolineas. Para esto, el magnate le dispone del dataset `aerolineas_licer.parquet`, el cual contiene el grado de satisfacci√≥n de los clientes frente a diferentes aspectos del vuelo. Las caracter√≠sticas del vuelo se definen a continuaci√≥n:\n",
    "\n",
    "- *Gender*: G√©nero de los pasajeros (Femenino, Masculino)\n",
    "- *Customer Type*: Tipo de cliente (Cliente habitual, cliente no habitual)\n",
    "- *Age*: Edad actual de los pasajeros\n",
    "- *Type of Travel*: Prop√≥sito del vuelo de los pasajeros (Viaje personal, Viaje de negocios)\n",
    "- *Class*: Clase de viaje en el avi√≥n de los pasajeros (Business, Eco, Eco Plus)\n",
    "- *Flight distance*: Distancia del vuelo de este viaje\n",
    "- *Inflight wifi service*: Nivel de satisfacci√≥n del servicio de wifi durante el vuelo (0:No Aplicable; 1-5)\n",
    "- *Departure/Arrival time convenient*: Nivel de satisfacci√≥n con la conveniencia del horario de salida/llegada\n",
    "- *Ease of Online booking*: Nivel de satisfacci√≥n con la facilidad de reserva en l√≠nea\n",
    "- *Gate location*: Nivel de satisfacci√≥n con la ubicaci√≥n de la puerta\n",
    "- *Food and drink*: Nivel de satisfacci√≥n con la comida y la bebida\n",
    "- *Online boarding*: Nivel de satisfacci√≥n con el embarque en l√≠nea\n",
    "- *Seat comfort*: Nivel de satisfacci√≥n con la comodidad del asiento\n",
    "- *Inflight entertainment*: Nivel de satisfacci√≥n con el entretenimiento durante el vuelo\n",
    "- *On-board service*: Nivel de satisfacci√≥n con el servicio a bordo\n",
    "- *Leg room service*: Nivel de satisfacci√≥n con el espacio para las piernas\n",
    "- *Baggage handling*: Nivel de satisfacci√≥n con el manejo del equipaje\n",
    "- *Check-in service*: Nivel de satisfacci√≥n con el servicio de check-in\n",
    "- *Inflight service*: Nivel de satisfacci√≥n con el servicio durante el vuelo\n",
    "- *Cleanliness*: Nivel de satisfacci√≥n con la limpieza\n",
    "- *Departure Delay in Minutes*: Minutos de retraso en la salida\n",
    "- *Arrival Delay in Minutes*: Minutos de retraso en la llegada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sOoIFHpw5xCW"
   },
   "source": [
    "En consideraci√≥n de lo anterior, realice las siguientes tareas:\n",
    "\n",
    "0. Ingeste el dataset a su ambiente de trabajo.\n",
    "\n",
    "1. Seleccione **s√≥lo las variables num√©ricas del dataset**.  Explique qu√© √©fectos podr√≠a causar el uso de variables categ√≥ricas en un algoritmo no supervisado. [2 punto]\n",
    "\n",
    "2. Realice una visualizaci√≥n de la distribuci√≥n de cada variable y analice cada una de estas distribuciones. [2 punto]\n",
    "\n",
    "3. Bas√°ndose en los gr√°ficos, eval√∫e la necesidad de escalar los datos y explique el motivo de su decisi√≥n. [2 puntos]\n",
    "\n",
    "4. Examine la correlaci√≥n entre las variables mediante un correlograma. [2 puntos]\n",
    "\n",
    "5. De acuerdo con los resultados obtenidos en 5, reduzca la dimensionalidad del conjunto de datos a cuatro variables, justificando su elecci√≥n respecto a las variables que decide eliminar. [2 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tO6tcVBCtxxS"
   },
   "source": [
    "**Respuesta:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.Ingeste el dataset a su ambiente de trabajo.\n",
    "df = pd.read_parquet(\"aerolineas_lucer.parquet\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pzHTZ17xveU_"
   },
   "outputs": [],
   "source": [
    "#1. Seleccione s√≥lo las variables num√©ricas del dataset. Explique qu√© √©fectos podr√≠a causar el uso de variables categ√≥ricas en un algoritmo no supervisado. [2 punto]\n",
    "numerical_columns = df.select_dtypes(['float', 'int']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Realice una visualizaci√≥n de la distribuci√≥n de cada variable y analice cada una de estas distribuciones. [2 punto]\n",
    "for col in numerical_columns:\n",
    "    fig = px.histogram(df, x=col, marginal=\"box\", title = 'Histogram of ' + col)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Bas√°ndose en los gr√°ficos, eval√∫e la necesidad de escalar los datos y explique el motivo de su decisi√≥n. \n",
    "Notamos que en todos los graficos las variables est√°n en la misma escala(0-5), excepto :\n",
    "* id\n",
    "* Age\n",
    "* Flight Distance\n",
    "* Departure Delay in Minutes\n",
    "* Arrival Delay Minutes\n",
    "\n",
    "Sin embargo, estas ultimas no nos sirven para analizar el nivel de satidfacci√≥n de los pasajeros, asi que las excluiremos de dataset a analizar.\n",
    "Dado lo anterior no es necesario escalar los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Examine la correlaci√≥n entre las variables mediante un correlograma. [2 puntos]\n",
    "numerical_columns = numerical_columns.drop(['id','Age','Flight Distance', 'Departure Delay in Minutes', 'Arrival Delay in Minutes'])\n",
    "\n",
    "correlaciones = df[numerical_columns].corr() \n",
    "mask = np.abs(correlaciones) < 0.4\n",
    "mas_correlaciones = correlaciones.mask(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(\n",
    "    mas_correlaciones,\n",
    "    #correlaciones,\n",
    "    aspect=\"16:9\",\n",
    "    title=\"Correlaci√≥n entre Variables\",\n",
    "    height=800,\n",
    "    zmin=-1,\n",
    "    color_continuous_midpoint=0,\n",
    "    zmax=1,\n",
    "    color_continuous_scale=px.colors.sequential.Viridis,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos las variables que presentan mayor correlaci√≥n entre si y notamos que podemos ordenar las relaciones as√≠:\n",
    "\n",
    "{Departure/Arrival time convenient - Gate location- Ease of Online booking}- Inflight wifi - Online boarding - {Seat comfort - Food and drink - cleanliness - enterteinment} - {on board service/inflight service-baggage handling}\n",
    "  \n",
    "* Leg room service: No se relaciona\n",
    "* Check-in service: No se relaciona\n",
    "\n",
    "Para que no haya redundancia elegiremos ambas variables que no tienen relaci√≥n con el resto y 'Online boarding' y 'Inflight wifi' ya que de alguna forma se relacionan con todo el resto de variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. De acuerdo con los resultados obtenidos, reduzca la dimensionalidad del conjunto de datos a cuatro variables, justificando su elecci√≥n respecto a las variables que decide eliminar\n",
    "\n",
    "select_columns = ['Checkin service', 'Leg room service', 'Online boarding', 'Inflight wifi service']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4b6c047d994f40ea9e78a36a777042e0",
    "deepnote_cell_type": "markdown",
    "id": "PNGfTgtkrqC9"
   },
   "source": [
    "## 3. Preprocesamiento üé≠. [10 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "713b3f0e61dd4841bb5b38c730d344d5",
    "deepnote_cell_type": "markdown",
    "id": "6RZD0fMNrqC-"
   },
   "source": [
    "<center>\n",
    "<img src=\"https://i.pinimg.com/originals/1e/a8/0e/1ea80e7cea0d429146580c7e91c5b944.gif\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "98400c7b5fec4af193eec3601f53891e",
    "deepnote_cell_type": "markdown",
    "id": "J6d4VEOTrqC-"
   },
   "source": [
    "Tras quedar satisfecho con los resultados presentados en el punto 2, el due√±o de la empresa ha solicitado que se preprocesen los datos mediante un `pipeline`. Es crucial que este proceso tenga en cuenta las observaciones derivadas de los an√°lisis anteriores. Adicionalmente, ha expresado su inter√©s en visualizar el conjunto de datos en un gr√°fico de dos o tres dimensiones.\n",
    "\n",
    "Bas√°ndose en los an√°lisis realizados anteriormente:\n",
    "1. Cree un `pipeline` que incluya PCA, utilizando las consideraciones mencionadas previamente para proyectar los datos a dos dimensiones. [4 puntos]\n",
    "2. Grafique los resultados obtenidos y comente lo visualizado. [6 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "paDSaGoq0OUp"
   },
   "source": [
    "**Respuestas:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "ad1e70818ad748638ca0927b07a76125",
    "deepnote_cell_type": "code",
    "id": "gBYG238wrqC-"
   },
   "outputs": [],
   "source": [
    "# Escriba su c√≥digo aqu√≠\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# 1.Cree un pipeline que incluya PCA, utilizando las consideraciones mencionadas previamente para proyectar los datos a dos dimensiones\n",
    "\n",
    "pca = ColumnTransformer([(\"PCA\", PCA(n_components=2), select_columns)] )\n",
    "\n",
    "pipe_1 = Pipeline([(\"Preprocesamiento_pca\", pca)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2.Grafique los resultados obtenidos y comente lo visualizado\n",
    "transformaciones = pipe_1.fit_transform(df[select_columns])\n",
    "#transformaciones\n",
    "df[\"x_PCA\"] = transformaciones[:, 0]\n",
    "df[\"y_PCA\"] = transformaciones[:, 1]\n",
    "px.scatter(df, x=\"x_PCA\", y= \"y_PCA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade nbformat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Respuesta:\n",
    "Vemos que al graficar las variables en una dimensi√≥n reducida, los datos muestran una agrupaci√≥n natural, indicando que se pueden clasificar en distintos clusters bien diferenciables segun sus caracter√≠sticas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "bd281470d3054764a63d857cfa7d52a6",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": [],
    "id": "7ENoOtIIrqC_"
   },
   "source": [
    "## 4. Outliers üö´üôÖ‚Äç‚ôÄÔ∏è‚ùåüôÖ‚Äç‚ôÇÔ∏è [10 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "db89e9c9f35c44abbd8991180226c0ea",
    "deepnote_cell_type": "markdown",
    "id": "fbGw6Sa-rqC_"
   },
   "source": [
    "<center>\n",
    "<img src=\"https://joachim-gassen.github.io/images/ani_sim_bad_leverage.gif\" width=250>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "3e2f59fa12954641af7a854a4e203694",
    "deepnote_cell_type": "markdown",
    "id": "nl_ccu9brqDA"
   },
   "source": [
    "Con el objetivo de mantener la claridad en su an√°lisis, Don Sergio le ha solicitado entrenar un modelo que identifique pasajeros con comportamientos altamente at√≠picos.\n",
    "\n",
    "1. Utilice `IsolationForest` para clasificar las anomal√≠as del dataset (sin aplicar PCA), configurando el modelo para que s√≥lo el 1% de los datos sean considerados an√≥malos. Aseg√∫rese de integrar esta tarea dentro de un `pipeline`. [3 puntos]\n",
    "\n",
    "2. Visualice los resultados en el gr√°fico de dos dimensiones previamente creado. [3 puntos]\n",
    "\n",
    "3. ¬øC√≥mo evaluar√≠a el rendimiento de su modelo en la detecci√≥n de anomal√≠as? [4 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5cS1FR00NlF"
   },
   "source": [
    "**Respuestas:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "be86896911244aa89e3b5f3f00a286af",
    "deepnote_cell_type": "code",
    "id": "iaPZFmjyrqDA"
   },
   "outputs": [],
   "source": [
    "# 1. Utilice `IsolationForest` para clasificar las anomal√≠as del dataset (sin aplicar PCA), configurando el modelo para que s√≥lo el 1% de los datos sean considerados an√≥malos. \n",
    "#Aseg√∫rese de integrar esta tarea dentro de un `pipeline`.\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "isfor = IsolationForest(contamination=0.01, random_state=0) #n_estimators=20, \n",
    "pipe_2 = Pipeline([(\"Preprocesamiento_isfor\",isfor)])\n",
    "outliers = pipe_2.fit(df[select_columns]).predict(df[select_columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Visualice los resultados en el gr√°fico de dos dimensiones previamente creado. \n",
    "df[\"out\"] = outliers.astype(str)\n",
    "px.scatter(df, x=\"x_PCA\", y=\"y_PCA\", color='out')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. ¬øC√≥mo evaluar√≠a el rendimiento de su modelo en la detecci√≥n de anomal√≠as?\n",
    "\n",
    "Analizando el gr√°fico obtenido de la reducci√≥n de dimensionalidad e idenificaci√≥n de outliers, vemos que el rendimiento del modelo no es muy bueno pues, si bien hay datos identificados como anomal√≠as que s√≠ se encuentran fuera de uno de los clusters naturales, tambi√©n hay datos marcados como outliers que estan sobre, o muy cercanos, a alguna de estas agrupaciones de datos. Adem√°s, tambi√©n se observan datos \"lejanos\" a los grupos que no fueron marcados, es decir, el modelo presetna errores de tipo falsos positivos y falsos negativos. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "3871e2fe5bdd422dbdbfaebf75503ae3",
    "deepnote_cell_type": "markdown",
    "id": "zQFTklmVrqDB"
   },
   "source": [
    "## 5. M√©tricas de Desempe√±o üöÄ [10 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "236333de6dd445c182aefcc507589325",
    "deepnote_cell_type": "markdown",
    "id": "YpNj4wbPrqDB"
   },
   "source": [
    "<center>\n",
    "<img src=\"https://giffiles.alphacoders.com/219/219081.gif\" width=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a7e1ceb91be94b1da2ab8be97dfac999",
    "deepnote_cell_type": "markdown",
    "id": "CR3hzRxrrqDB"
   },
   "source": [
    "Motivado por incrementar su fortuna, Don Sergio le solicita entrenar un modelo que le permita segmentar a los pasajeros en grupos distintos, con el objetivo de optimizar las diversas campa√±as de marketing dise√±adas por su equipo. Para ello, le se pide realizar las siguientes tareas:\n",
    "\n",
    "1. Utilizar el modelo **Gaussian Mixture** y explore diferentes configuraciones de n√∫mero de cl√∫sters, espec√≠ficamente entre 3 y 8. Aseg√∫rese de integrar esta operaci√≥n dentro de un `pipeline`. [4 puntos]\n",
    "2. Explique cu√°l ser√≠a el criterio adecuado para seleccionar el n√∫mero √≥ptimo de cl√∫sters. **Justifique de forma estadistica y a traves de gr√°ficos.** [6 puntos]\n",
    "\n",
    "> **HINT:** Se recomienda investigar sobre los criterios AIC y BIC para esta tarea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jt_T_zTg0MXB"
   },
   "source": [
    "**Respuestas:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "6d3d1bb3fda14321984466d9101a775a",
    "deepnote_cell_type": "code",
    "id": "5GeUb9J3rqDB"
   },
   "outputs": [],
   "source": [
    "#1. Utilizar el modelo **Gaussian Mixture** y explore diferentes configuraciones de n√∫mero de cl√∫sters, espec√≠ficamente entre 3 y 8. \n",
    "# Aseg√∫rese de integrar esta operaci√≥n dentro de un `pipeline`.\n",
    "\n",
    "from sklearn.mixture import GaussianMixture \n",
    "\n",
    "def gmm(n):\n",
    "    gmm = GaussianMixture(n_components = n, random_state=1) \n",
    "    return gmm\n",
    "    \n",
    "pipe_3 = Pipeline([(\"Preprocesamiento_gmm3\", gmm(3)),\n",
    "                   (\"Preprocesamiento_gmm4\", gmm(4)),\n",
    "                   (\"Preprocesamiento_gmm5\", gmm(5)),\n",
    "                   (\"Preprocesamiento_gmm6\", gmm(6)),\n",
    "                   (\"Preprocesamiento_gmm7\", gmm(7)), \n",
    "                   (\"Preprocesamiento_gmm8\", gmm(8))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Explique cu√°l ser√≠a el criterio adecuado para seleccionar el n√∫mero √≥ptimo de cl√∫sters:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para seleccionar el n√∫mero √≥ptimo de clusters se puede realizar un m√©todo similar al \"m√©todo del codo\" utilizado para clusterizaci√≥n con Kmeans, en donde se recurre a m√©tricas como el \"Akaike information criterion\" (AIC), o bien, el \"Bayesian information criterion\" (BIC), las cuales indican qu√© tan bien se ajustan los datos al modelo creado. En la implementaci√≥n realizada a continuaci√≥n, cuanto m√°s bajo el valor (de ambas m√©tricas), mejor es el resultado del modelo. \n",
    "\n",
    "A continuaci√≥n se calculan las m√©trica BIC y AIC del modelo Gaussian Mixture para n_components entre 3 y 8:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listas de valores BIC y AIC:\n",
    "valores_bic = []\n",
    "valores_aic = []\n",
    "\n",
    "# entrenamos el modelo y calculamos valores bic y aic para cada cantidad de componentes\n",
    "for modelo_i in pipe_3:\n",
    "    gmm_i = modelo_i.fit(df[select_columns])\n",
    "    valores_bic.append(gmm_i.bic(df[select_columns]))\n",
    "    valores_aic.append(gmm_i.aic(df[select_columns]))\n",
    "\n",
    "\n",
    "components = [pipe_3[i].n_components for i in range(len(pipe_3))]\n",
    "data = {'components': components, 'valores_bic': valores_bic, 'valores_aic': valores_aic}\n",
    "df_bic_aic = pd.DataFrame(data)\n",
    "\n",
    "# Graficamos\n",
    "fig = px.line(df_bic_aic, x='components', y=['valores_bic', 'valores_aic'], \n",
    "              labels={'components': 'N√∫mero de componentes', 'value': 'Valores'}, \n",
    "              title='Valores BIC y AIC de modelo Gaussian Mixture para valores de n_components')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se aprecia en el gr√°fico, el modelo alcanza un m√≠nimo valor en ambos criterios (BIC y AIC) utilizando 6 componentes, por lo que podemos asumir que $n=6$ es la cantidad √≥ptima de clusters a utilizar en el modelo.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "dd342e336254418ba766b29dce16b267",
    "deepnote_cell_type": "markdown",
    "id": "P9CERnaerqDC"
   },
   "source": [
    "## 6. An√°lisis de resultados üìä [10 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "953b5ad01a704b50b899db7176d1b7b2",
    "deepnote_cell_type": "markdown",
    "id": "I1yNa111rqDC"
   },
   "source": [
    "<center>\n",
    "<img src=\"https://i.gifer.com/7wTk.gif\" width=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "fd90e2f135404353ac0b5ab844936ca7",
    "deepnote_cell_type": "markdown",
    "id": "dg0Qx4RZrqDC"
   },
   "source": [
    "Una vez identificado el n√∫mero √≥ptimo de cl√∫sters, se le pide realizar lo siguiente:\n",
    "\n",
    "1. Utilizar la proyecci√≥n en dos dimensiones para visualizar cada cl√∫ster claramente. [2 puntos]\n",
    "\n",
    "2. ¬øEs posible distinguir claramente entre los cl√∫sters generados? [2 puntos]\n",
    "\n",
    "3. Proporcionar una descripci√≥n breve de cada cl√∫ster utilizando estad√≠sticas descriptivas b√°sicas, como la media y la desviaci√≥n est√°ndar, para resumir las caracter√≠sticas de las variables utilizadas en estos algoritmos. [2 puntos]\n",
    "\n",
    "4. Proceda a visualizar los cl√∫sters en tres dimensiones para una perspectiva m√°s detallada. [2 puntos]\n",
    "\n",
    "5. ¬øC√≥mo afecta esto a sus conclusiones anteriores? [2 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CRN0zZip0IMB"
   },
   "source": [
    "**Respuestas:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_3[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "9abf4dbc643e40cebe99fcb1ff3ff413",
    "deepnote_cell_type": "code",
    "id": "XmZrz15GrqDC"
   },
   "outputs": [],
   "source": [
    "# 1. Utilizar la proyecci√≥n en dos dimensiones para visualizar cada cl√∫ster claramente.\n",
    "clusters_gmm6 = pipe_3[3].fit(df[select_columns]).predict(df[select_columns])\n",
    "\n",
    "df['gmm_labels'] = clusters_gmm6.astype(str)\n",
    "px.scatter(df, x=\"x_PCA\", y=\"y_PCA\", color='gmm_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. ¬øEs posible distinguir claramente entre los cl√∫sters generados?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si bien se pueden distinguir los clusters no es tan claro la forma en que se agupan. Se puede pbservar que la forma en que se generaron los clusters no es coherente con la agrupaci√≥n natural de los datos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 3. Proporcionar una descripci√≥n breve de cada cl√∫ster utilizando estad√≠sticas descriptivas b√°sicas, como la media y la desviaci√≥n est√°ndar, para resumir las caracter√≠sticas de las variables utilizadas en estos algoritmos. [2 puntos]\n",
    "df_descr = df[select_columns]\n",
    "df_descr['gmm_labels'] = df['gmm_labels']\n",
    "\n",
    "df_descr.groupby('gmm_labels').agg(['min', 'max', 'mean', 'std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Proceda a visualizar los cl√∫sters en tres dimensiones para una perspectiva m√°s detallada. [2 puntos]\n",
    "pca3 = ColumnTransformer([(\"PCA\", PCA(n_components=3), select_columns)] )\n",
    "\n",
    "pipe_4 = Pipeline([(\"Preprocesamiento_pca_3d\", pca3)])\n",
    "\n",
    "\n",
    "projections_3d = pipe_4.fit_transform(df[select_columns])\n",
    "\n",
    "df_3d = pd.DataFrame(data = projections_3d)\n",
    "df_3d['gmm_labels'] = df['gmm_labels'].values\n",
    "\n",
    "df_3d.columns = ['component_1', 'component_2', 'component_3', 'gmm_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(df_3d, x='component_1', y='component_2', z='component_3', color='gmm_labels')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. ¬øC√≥mo afecta esto a sus conclusiones anteriores? [2 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esta nueva visualizaci√≥n en 3d de los clusters generados por el modelo, podemos observar que los resultados de las agrupaciones son mucho m√°s coherentes, en comparaci√≥n a la visualizaci√≥n en 2d. Si bien los grupos generados no son separables en la visualizaci√≥n 3d, se aprecia mucho m√°s claramente la forma en qeu se agrupan.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "7cb425aec99b4079954fd707109c42c3",
  "deepnote_persisted_session": {
   "createdAt": "2024-04-26T06:15:51.197Z"
  },
  "kernelspec": {
   "display_name": "MNE",
   "language": "python",
   "name": "mne"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
